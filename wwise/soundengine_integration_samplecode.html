<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.20"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Integration Demo Sample</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="akdoxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Wwise SDK 2023.1.0 - Windows
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.20 -->
</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Integration Demo Sample </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>The Integration Demo application contains a series of demonstrations that show how to integrate various features of the sound engine in your game.</p>
<table border="0" cellspacing="0" cellpadding="2">
<tr>
<td valign="top"><img src="images/Note.gif" alt="" class="inline"/></td><td><b>Note:</b> All code presented in this section is available in a sample project in the <code>samples\IntegrationDemo\</code> directory. </td></tr>
</table>
<h1><a class="anchor" id="integrationdemo_wwiseproject"></a>
The Wwise Project</h1>
<p>The Wwise project for this program is also available in <code>samples\IntegrationDemo\WwiseProject</code>.</p>
<table border="0" cellspacing="0" cellpadding="2">
<tr>
<td valign="top"><img src="images/Note.gif" alt="" class="inline"/></td><td><p class="starttd"><b>Note:</b> The Wwise project for this program uses various audio file conversion formats, some of which may not be available depending on which platforms are supported by your Wwise installation. After opening the project in Wwise, you may see warnings such as:</p>
<pre><code>\Actor-Mixer Hierarchy\Dialogues\Captain_A\UNA-BM-AL_01\UNA-BM-AL_01</code> uses the conversion plugin 'XMA', which is not installed.</pre><p class="endtd">You can remove these messages by changing the conversion format for all unavailable platforms to PCM. Refer to the following topic in the Wwise User Guide for more information: Converting Audio Files. </p>
</td></tr>
</table>
<p>SoundBanks for this project are also installed with the SDK in the <code>samples\IntegrationDemo\WwiseProject\GeneratedSoundBanks</code> folder.</p>
<p>To regenerate the SoundBanks, make sure to do the following in the SoundBank Manager:</p><ul>
<li>Check all banks in the SoundBanks list.</li>
<li>Check off all platforms that are being tested.</li>
<li>Check all languages in the Languages list.</li>
</ul>
<p>Once these settings are correct, you can click on <b>Generate</b> in the SoundBank Manager to generate the banks.</p>
<h1><a class="anchor" id="integrationdemo_building_and_running"></a>
Building and Running the Demo</h1>
<p>The Integration Demo binaries are available in the <code>\[Debug|Profile|Release]\bin</code> directory. If you would like to rebuild the application yourself, follow these steps:</p>
<div platform="Windows" open="1"></div> <h2><a class="anchor" id="integrationdemo_building_win"></a>
Windows</h2>
<ul>
<li>Confirm that the version of the DirectX SDK installed on your machine matches the one mentioned in <a class="el" href="reference_platform.html">Platform Requirements</a>.</li>
<li>Generate the Integration Demo SoundBanks for Windows in their default paths.</li>
<li>Open the solution found in <code>samples\IntegrationDemo\Windows</code> and build using the desired configuration.</li>
</ul>
<p>To run the Integration Demo, simply launch the executable found in the directory mentioned above. </p><div platform="Windows" open="0"></div><h1><a class="anchor" id="integrationdemo_usage"></a>
Usage Instructions</h1>
<p>You can navigate through the Integration Demo on Windows using either the keyboard, a connected controller, or any DirectInput compatible device.</p><ul>
<li>To navigate between controls on a page, use the up and down arrow keys or the up and down buttons on a gamepad's directional pad.</li>
<li>To activate the selected control, hit the Enter key or the A/X button on a gamepad.</li>
<li>To go back a page in the menu, hit the Escape key or the B/O button on a gamepad.</li>
</ul>
<p>Certain controls (such as Toggle Controls and Numeric Sliders) allow you to change values. To change their values, hit the left and right arrow keys or the left and right buttons on a gamepad's directional pad.</p>
<table border="0" cellspacing="0" cellpadding="2">
<tr>
<td valign="top"><img src="images/Tip.gif" alt="" class="inline"/></td><td><b>Tip:</b> The application has an online help feature! To access the Help page, press F1 on the keyboard or the START button on a gamepad. </td></tr>
</table>
<h1><a class="anchor" id="integrationdemo_demos"></a>
The Demos</h1>
<p><b>The code behind each demonstration can be found in the <code>samples\IntegrationDemo\DemoPages</code> directory.</b> For example, the code for the Localization demo will be in the <code>DemoLocalization.h</code> and <code>DemoLocalization.cpp</code> files in that directory.</p>
<table border="0" cellspacing="0" cellpadding="2">
<tr>
<td valign="top"><img src="images/Tip.gif" alt="" class="inline"/></td><td><b>Tip:</b> Pertinent information about each demo can also be found in the Integration Demo application's online help. </td></tr>
</table>
<h2><a class="anchor" id="integration_demos_dialogue"></a>
Dialogue</h2>
<h3><a class="anchor" id="integrationdemo_demos_localization"></a>
Localization Demo</h3>
<p>This demo shows how to implement localized audio. Localized sound objects are found in language-specific SoundBanks in subdirectories in the SoundBank generation directory. We achieve the localization effect by unloading the current SoundBank and reloading the desired language-specific SoundBank.</p>
<p>Use the <b>Language</b> toggle control to switch the current language. Then press the <b>Say Hello</b> button to hear a greeting in the selected language.</p>
<p>For more information about languages and localization, see <a class="el" href="soundengine_languages.html">Integration Details - Languages and Voices</a>.</p>
<h3><a class="anchor" id="integrationdemo_demos_dynamic_dialogue"></a>
Dynamic Dialogue Demo</h3>
<p>The Dynamic Dialogue demo runs through a series of tests that use Wwise's Dynamic Dialogue features. Each of these tests demonstrates a different control flow so that you can hear the effect it produces:</p><ul>
<li>Test 1: Shows how to play a simple dynamic sequence using Wwise IDs.</li>
<li>Test 2: Like test 1, but uses strings instead of IDs.</li>
<li>Test 3: Shows how to add an item to a dynamic playlist during playback.</li>
<li>Test 4: Shows how to insert an item into the dynamic playlist during playback.</li>
<li>Test 5: Shows what happens when an item is added to an empty playlist.</li>
<li>Test 6: Shows how to use the <b>Stop</b> call on a dynamic sequence.</li>
<li>Test 7: Shows how to use the <b>Break</b> call on a dynamic sequence.</li>
<li>Test 8: Shows how to use the <b>Pause</b> and <b>Resume</b> calls on a dynamic sequence.</li>
<li>Test 9: Shows how to use the <b>Delay</b> call when enqueuing an item to a dynamic sequence.</li>
<li>Test 10: Shows how to clear a playlist during playback.</li>
<li>Test 11: Shows what happens when the playlist is stopped and cleared.</li>
<li>Test 12: Shows what happens when <b>Break</b> is called on a playlist and it clears.</li>
<li>Test 13: Shows what happens when a playlist is paused and cleared.</li>
<li>Test 14: Shows how to use a callback function with custom parameters when working with Dynamic Dialogue.</li>
<li>Test 15: Shows how to use a callback to perform tasks (in this case, to cancel playback after three items have played).</li>
<li>Test 16: Shows how to use a callback to perform tasks (in this case, to play a second sequence after the first sequence ends).</li>
<li>Test 17: Show how to use Wwise Events in conjunction with Dynamic Dialogue.</li>
</ul>
<p>For more information about Dynamic Dialogue, see <a class="el" href="soundengine_dynamicdialogue.html">Integration Details - Dynamic Dialogue</a></p>
<h2><a class="anchor" id="integrationdemo_demos_rtpc"></a>
RTPC (Car Engine)</h2>
<p>This demo shows how to use RTPCs. The RPM numeric slider is linked with an RTPC value (RPM) associated with the engine. Press the <b>Start Engine</b> button to start/stop car engine audio. Use the RPM slider to change the RTPC value and hear the effect.</p>
<p>For more information about RTPCs, see <a class="el" href="soundengine_rtpc.html">Integration Details - RTPCs</a>.</p>
<h2><a class="anchor" id="integrationdemo_demos_footsteps"></a>
Footsteps</h2>
<p>This demo shows various ways to implement footsteps in a game. It also shows surface-driven bank management to minimize both media and metadata memory when a surface isn't in use. Finally, this demo also shows a very simple case of environmental effects.</p>
<p>In this example, the footstep sounds are modified by two variables: walking speed, and walker weight.</p>
<ul>
<li>Walking Speed issues (Footstep_Speed RTPC) This project supports a smooth transition from walking to running in almost all cases. For this variable, we assume the following: the faster you walk, the shorter the footstep and the harder you hit the ground. This translates in Pitch and Volume changes respectively. Look for RTPC on these parameters in the project. The Speed RTPC is driven directly by the joystick displacement in this demo.</li>
<li>Walker Weight issues (Footstep_Weight RTPC) The footstep structure supports various walker weights. We assume that in real life a heavier walker will have a longer footstep and that it will be more muffled. This translates in Pitch and LPF changes respectively. Look for the RTPC on these parameters in the project.</li>
</ul>
<p>With each surface, we show a different way of dealing with the sound samples and variables. These are only suggestions and ideas that you can use in your own structure.</p>
<ul>
<li>Gravel Our gravel samples are very similar, so it won't give us anything more to have a lot of samples of this surface. More variation is obtained with a bit of Volume, LPF, and Pitch randomization. The Weight influence is done through the EQ effect with its gain parameters driven by the Weight RTPC. For light footsteps, the higher frequencies are boosted, and it's the reverse for heavy footsteps. Note the RTPC's effect on Pitch and Volume.</li>
<li>Wood For the wood surface, the walking and running samples were very different, as were the heavy and light footsteps. So, this was organized in a more traditional Switch hierarchy. Both Switch Containers are driven by an RTPC-driven Switch (look in the GameSync tab for Footstep_Gait and Footstep_Weight).</li>
<li>Dirt Samples for walking and running on this surface were somewhat similar, so we decided to do the transition with a Blend Container. RTPCs on Pitch and Volume were used to take the Weight into account.</li>
</ul>
<p><b>Bank management</b> In the Footsteps demo, the banks were divided into four media banks (one per surface). We divided the screen in four with a buffer zone between each surface where both banks are loaded. This is to avoid a gap in the footsteps due to bank loading. In the SoundBank Manager, look at the GameSync tab. Note that each surface bank includes only the corresponding surface Switch. This will include only the hierarchy related to that Switch in the bank - nothing else. In a large game, this setup has the advantage of limiting the amount of unused samples in a particular scenario, thus limiting the memory used. For level or section-based games, it is easy to identify the surfaces used as they are known from the design stage. For open games, this is trickier and depends a lot on the organization of your game; but, it can still be achieved. For example, it is useless to keep the "snow and ice" surface sounds in memory if your player is currently in a warm city and won't be moving toward colder settings for a long time.</p>
<h2><a class="anchor" id="integrationdemo_demos_markers"></a>
Subtitles/Markers</h2>
<p>This demo shows how you can set up a callback function to receive notification when markers inside a sound file are hit. For this demonstration, we are using the markers to synchronize subtitles with the audio track.</p>
<p>For more information on markers, see <a class="el" href="soundengine_markers.html">Integrating Markers</a>.</p>
<h2><a class="anchor" id="integrationdemo_demos_music_midi"></a>
Music/MIDI</h2>
<h3><a class="anchor" id="integrationdemo_demos_music_callbacks_music_sync"></a>
Music sync callback demo</h3>
<p>This demo shows how to use music callbacks in general. Beat and bar notifications are generated from music tempo and time signature information.</p>
<h3><a class="anchor" id="integrationdemo_demos_music_callbacks_music_playlist"></a>
Music playlist callback demo</h3>
<p>This example shows how to force a random playlist to select its next item sequentially. The playlist item may be stopped via the callback as well.</p>
<h3><a class="anchor" id="integrationdemo_demos_music_callbacks_midi"></a>
MIDI callback demo</h3>
<p>Shows MIDI messages the game can receive using callbacks. MIDI messages include the MIDI notes, CC values, Pitch Bend, After Touch, and Program Changes.</p>
<p>For more information on music callbacks, refer to <a class="el" href="soundengine_music_callbacks.html">Integration Details - Music Callbacks</a>.</p>
<h3><a class="anchor" id="integrationdemo_demos_interactive_music"></a>
Interactive Music Demo</h3>
<p>This example uses a Music Switch Container. Try switching the States by triggering the Event listed in the demo page. Switching States might produce a result that is immediate or occurs at the time specified in the rules of the Music Container.</p>
<h3><a class="anchor" id="integrationdemo_demos_midi_api"></a>
MIDI API Demo</h3>
<p>This example demonstrates the use of the MIDI API. Press the <b>Start Metronome</b> button to simulate an active metronome. Then select the <b>BPM</b> slider and press LEFT or RIGHT to change its value. The demo uses a registered callback function to post MIDI Events to the sound engine via the <code>PostMIDIOnEvent</code> function.</p>
<h3><a class="anchor" id="integration_demos_bgm"></a>
Background Music Demo</h3>
<p>This example shows how to handle the DVR legal requirements for Xbox One and PS4. Since many games include copyrighted music, it is often not permitted to record it with the built-in DVR. This demo shows the differences between a sound that is recorded by the DVR and one that isn't. Please refer to the Wwise Project and check the setup of the sounds in the <em>BGMDemo</em> folder, paying attention to their routing and which Audio Device they use. The Non-Recordable sound will be routed to a bus that outputs to the <em>DVR_Bypass</em> output.</p>
<dl class="section see"><dt>See also</dt><dd><ul>
<li><a class="el" href="integrating_secondary_outputs.html">Integrating Secondary Outputs</a></li>
</ul>
</dd></dl>
<h2><a class="anchor" id="integrationdemo_demos_positioning"></a>
Positioning</h2>
<p>These demos show various ways to do 3D positioning in Wwise.</p>
<p>A helicopter sound starts playing as soon as you enter the page. Move the 'o' around in X and Z, the plane of the screen, using the following keys:</p><ul>
<li>Right Stick</li>
<li>Arrow Keys/Dpad And hear the sound move along with it. Coordinates are displayed at the bottom-left of the screen.</li>
</ul>
<h3><a class="anchor" id="integrationdemo_demos_positioning_position"></a>
Position Demo</h3>
<p>This demo sets only a single position.</p>
<h3><a class="anchor" id="integrationdemo_demos_positioning_mutiposition"></a>
Multi-Position Demo</h3>
<p>This demo sets two positions.</p>
<h3><a class="anchor" id="integrationdemo_demos_positioning_3dbus_clustering"></a>
3D Bus: Clustering/3D Submix</h3>
<p>This demos shows positioning applied only in the bus hierarchy. With Position + Orientation 3D Spatialization and Attenuation applied to the bus alone, the sound engine only applies the spatialization after the 3 child sounds are mixed together.</p>
<h3><a class="anchor" id="integrationdemo_demos_positioning_3dbus_portalroom"></a>
3D Bus: 3D Portal and Standard Room</h3>
<p>This demo illustrates how a movable emitter and listener can interact with each other. Notably, a Room with a Portal shows:</p><ul>
<li>how an aux bus simulates a room that the listener is currently inside;</li>
<li>how a 3D-bus chain, 'Room1' -&gt; 'Wet_Path_3D', simulates a room that the listener is not inside.</li>
</ul>
<p>The 3D bus applies a reverb Effect, after which the output is positioned and spatialized before being mixed in the Master Audio Bus.</p>
<h3><a class="anchor" id="integrationdemo_demos_positioning_3dbus_2xportal"></a>
3D Bus: 2X 3D Portal</h3>
<p>This demo allows the experience of a movable emitter and listener interacting with each other in combination with two different "Portaled" Rooms. Depending on the positions of the game objects, the Rooms may be close enough to be excited by the emitter output.</p>
<p>The 3D bus applies a reverb Effect, after which the output is positioned and spatialized before being mixed in the Master Audio Bus.</p>
<h2><a class="anchor" id="integrationdemo_demos_spatialaudio"></a>
Spatial Audio</h2>
<p>These demos show various ways to use Spatial Audio to model sound propagation across Rooms, Portals, and Geometry.</p>
<p>Each demo page includes a movable emitter and a movable listener. You can offset the listener from a Distance Probe to simulate a third-person listening experience.</p>
<dl class="section see"><dt>See also</dt><dd><ul>
<li><a class="el" href="spatial_audio.html">Spatial Audio</a></li>
</ul>
</dd></dl>
<h3><a class="anchor" id="integrationdemo_demos_spatialaudio_portal"></a>
Portal Demo</h3>
<p>This demo shows the effect of Portals in Spatial Audio positioning. There are two Rooms with Portals and visible sound propagation paths. The resulting diffraction and transmission amounts are displayed in the lower-left corner. Same-room obstruction (emitter-listener and portal-listener) is calculated through a combination of Portal-driven propagation and a native game-side obstruction algorithm. Game object spread is calculated for the emitter with its set radial value. Finally, this demo shows how to use a Room to play multi-channel ambient sounds / room tones that contract and become point sources at portals.</p>
<dl class="section see"><dt>See also</dt><dd><ul>
<li><a class="el" href="using_rooms_and_portals.html">Rooms and Portals</a></li>
</ul>
</dd></dl>
<h3><a class="anchor" id="integrationdemo_demos_spatialaudio_portal_geometry"></a>
Portal and Geometry Demo</h3>
<p>This demo shows the effect of Portals in conjunction with the Spatial Audio Geometry API. There are two Rooms with Portals, Geometry for the wall inside and outside of the Room, an obstacle and visible sound propagation paths. The resulting diffraction and transmission amounts are displayed in the lower-left corner. Spatial Audio is set up so that diffraction/transmission controls both project-wide obstruction and the built-in diffraction/transmission parameter, although only the former is used in the Wwise project. Spatial Audio handles diffraction and transmission using Portals and Geometry respectively. The demo does not compute additional obstruction and occlusion.</p>
<h3><a class="anchor" id="integrationdemo_demos_spatialaudio_geometry"></a>
Geometry Demo</h3>
<p>This demo showcases the Wwise Spatial Audio Geometry API, usable for direct (dry) path diffraction and transmission. There are two walls and visible diffraction paths. The resulting diffraction and transmission amounts are displayed in the lower-left corner. Spatial Audio is set up so that diffraction/transmission controls both project-wide obstruction and the built-in diffraction/transmission parameter, although only the former is used in the project.</p>
<dl class="section see"><dt>See also</dt><dd><ul>
<li><a class="el" href="spatial_audio_apigeometry_diffract.html">Using the Geometry API for Simulating Diffraction and Transmission</a></li>
</ul>
</dd></dl>
<h3><a class="anchor" id="integrationdemo_demos_spatialaudio_reflect"></a>
Reflect Demo</h3>
<p>This demo showcases the Wwise Reflect plug-in using the Geometry API to simulate early reflection. There is a room and a separate wall, defined by Spatial Audio Geometry, and visible reflection paths. Spatial Audio is set up with a reflection order displayed in the lower-left corner. Additionally, Spatial Audio allows reflection paths to diffract. The room Geometry in this demo can change texture and be scaled in size demonstrating the adaptability of the Geometry API.</p>
<dl class="section see"><dt>See also</dt><dd><ul>
<li><a class="el" href="spatial_audio_apigeometry_er.html">Using the Geometry API for Simulating Early Reflections</a></li>
<li>Geometric Diffraction of Early Reflections</li>
</ul>
</dd></dl>
<h3><a class="anchor" id="integrationdemo_demos_spatialaudio_portalandreflect"></a>
Portal and Reflect Demo</h3>
<p>This demo showcases the Reflect plug-in within the context of Rooms and Portals. There are five Rooms, connected by Portals that can be toggled open or closed, some additional walls defined by Spatial Audio Geometry, and visible reflection paths.</p>
<h3><a class="anchor" id="integrationdemo_demos_spatialaudio_reverbzone"></a>
Reverb Zone Demo</h3>
<p>This demo demonstrates the use of a Reverb Zone to create a space that has its own reverb effect and transitions into the outside Room without the use of Portals. There is a Room with a Portal that connects to a Reverb Zone, forming something like a covered balcony. The Reverb Zone's parent is the outdoor Room. There is also Geometry outside to show how paths can diffract around geometry, pass through the transparent surfaces of the Reverb Zone, and then continue through portals.</p>
<dl class="section see"><dt>See also</dt><dd><ul>
<li><a class="el" href="spatial_audio_roomsportals_reverbzones.html">Using Reverb Zones</a></li>
</ul>
</dd></dl>
<h2><a class="anchor" id="integration_demos_bank"></a>
Bank &amp; Event Loading</h2>
<h3><a class="anchor" id="integration_demos_bank_prepare"></a>
Prepare Event/Bank Demo</h3>
<p>This page shows how to use the PrepareBank and PrepareEvent API functions.</p>
<p>When the page is loaded, a PrepareBank operation loads the lightweight structure and event data referenced by this demo, without loading any actual media into memory. When the user moves the cursor to an area button, a PrepareEvent operation loads the corresponding media file (a .wem file on disk) into memory in anticipation of a future PostEvent. When the user finally enters the area, the event is posted and the media is ready to play.</p>
<h3><a class="anchor" id="integrationdemo_demos_externalsources"></a>
External Sources Demo</h3>
<p>This demo shows how to use external sources. Both buttons play the same sound structure but set up at run-time with either sources "1", "2" and "3", or sources "4", "5" and "6".</p>
<dl class="section see"><dt>See also</dt><dd><ul>
<li><a class="el" href="integrating_external_sources.html">Integrating External Sources</a></li>
</ul>
</dd></dl>
<p>Additionally, the external sources are packaged in the File Packager and loaded when opening the demo page. Refer to the Wwise Help for more information on the File Packager, and to the <a class="el" href="streamingdevicemanager.html">Streaming / Stream Manager</a> chapter for more details on the run-time aspect of file packages.</p>
<h3><a class="anchor" id="integration_demos_autobanks"></a>
Autobanks Demo</h3>
<p>This demo demonstrates the pros and cons of automatic event bank generation. When this option is selected in the Project Settings, Wwise generates individual banks for any events that are not contained in manually created banks. However, these auto-banks do not contain any media, only structure and event data. To load media associated with these events, the game must call either AK::SoundEngine::PrepareEvent or AK::SoundEngine::SetMedia.</p>
<h2><a class="anchor" id="integrationdemo_demos_micro"></a>
Microphone/AudioInput Demo</h2>
<p>This demo shows how to record audio from a microphone and input it in the Wwise sound engine. In the Integration Demo, select the <b>Microphone Demo</b> and speak into the microphone to hear your voice played back by the Wwise sound engine. Toggle the <b>Enable Delay</b> to hear an example of how audio data fed to the Audio Input plug-in can be processed like any other sound created in Wwise.</p>
<p>Each platform has a very different core API to access the microphone. Check the <code>SoundInput</code> and <code>SoundInputMgr</code> classes in the Integration Demo code to see how they interact with the AudioInput plug-in.</p>
<table border="0" cellspacing="0" cellpadding="2">
<tr>
<td valign="top"><img src="images/Note.gif" alt="" class="inline"/></td><td><b>Note:</b> This demo is available on the following platforms: Windows, macOS, iOS, and tvOS. </td></tr>
</table>
<dl class="section see"><dt>See also</dt><dd><ul>
<li><a class="el" href="referencematerial_audioinput.html">Audio Input Source Plug-in</a>.</li>
</ul>
</dd></dl>
<h2><a class="anchor" id="integrationdemo_demos_motion"></a>
Motion Demo</h2>
<p>This is a multiplayer demonstration which shows how to integrate Wwise's motion engine into your game.</p>
<p>In this demonstration, each player has the option to either close a door in the environment or to shoot a gun that they are holding. A listener is set for each player which is active on the door game object as well as the player's own gun. This way, if any player closes the door in the environment, all players receive force feedback reactions. However, only the players who fired their weapon receive force feedback for that Event. Additionally, on PS4 and PS5, the gun sound will only play on the gamepad speaker of each player.</p>
<div platform="Windows" open="1"></div> <table border="0" cellspacing="0" cellpadding="2">
<tr>
<td valign="top"><img src="images/Note.gif" alt="" class="inline"/></td><td><b>Note:</b> On Windows, a player using a keyboard should plug in a gamepad to participate in this demo. </td></tr>
</table>
<div platform="Windows" open="0"></div><p>This code demonstrates the use of secondary outputs, Wwise Motion, and Listener/Emitter management.</p>
<dl class="section see"><dt>See also</dt><dd><ul>
<li><a class="el" href="integrating_secondary_outputs.html">Integrating Secondary Outputs</a></li>
<li><a class="el" href="integrating_elements_motion.html">Integrating Wwise Motion</a></li>
<li><a class="el" href="soundengine_listeners.html">Integrating Listeners</a></li>
</ul>
</dd></dl>
<h2><a class="anchor" id="integrationdemo_demos_options"></a>
Options Page</h2>
<p>This page allows viewing of several initialization settings for the Sound Engine. You can also choose the audio output for the whole application. The sample code shows how to initialize &amp; terminate the Sound Engine and also how to select different physical audio outputs. Please refer to the specific sections below for more details on the Sound Engine initialization.</p>
<dl class="section see"><dt>See also</dt><dd><ul>
<li>AK::SoundEngine::Init</li>
<li><a class="el" href="struct_ak_init_settings.html">AkInitSettings</a></li>
<li><a class="el" href="struct_ak_platform_init_settings.html">AkPlatformInitSettings</a></li>
<li><a class="el" href="struct_ak_mem_settings.html">AkMemSettings</a></li>
<li><a class="el" href="struct_ak_comm_settings.html">AkCommSettings</a></li>
<li><a class="el" href="integrating_secondary_outputs.html">Integrating Secondary Outputs</a></li>
</ul>
</dd></dl>
<h1><a class="anchor" id="integrationdemo_more"></a>
More Sample Code</h1>
<p>The Integration Demo as well as its Wwise Project are kept very simple in order to demonstrate the basics of sound engine integration. For a more realistic integration project, refer to the AkCube Sound Engine Integration Sample Project. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</body>
</html>

